{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import random\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines that could not be parsed:  1\n",
      "\n",
      "      Found 133851 words\n",
      "      Sample word:\n",
      "          Word(written='disappeared', phonetic=['D', 'IH2', 'S', 'AH0', 'P', 'IH1', 'R', 'D'])\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "Word = namedtuple('Word', ['written', 'phonetic'])\n",
    "\n",
    "\n",
    "def load_words():\n",
    "    \"\"\"Loads the words from the CMU phonetic dictionary and parses them into Word objects\n",
    "    \n",
    "    Returns:\n",
    "        list, of Word objects \n",
    "    \"\"\"\n",
    "    words = []\n",
    "    bad_lines = 0\n",
    "    with open('data/cmudict-0.7b', 'rb') as dict_handle:\n",
    "        for line in dict_handle:\n",
    "            try:\n",
    "                line = line.decode(\"utf-8\") \n",
    "            except:\n",
    "                bad_lines += 1\n",
    "                continue\n",
    "                \n",
    "            if line[0] == ';' or len(line) < 2:\n",
    "                continue # Header or comment line\n",
    "\n",
    "            line_chunks = str(line[:-1]).split(' ')\n",
    "            written = line_chunks[0].lower()\n",
    "            phonetic = [phone for phone in line_chunks[1:] if len(phone) >= 1]\n",
    "            words.append(Word(written, phonetic))\n",
    "            \n",
    "    print('Number of lines that could not be parsed: ', bad_lines)\n",
    "    return words\n",
    "\n",
    "# Grab the words and check they loaded correctly.\n",
    "words = load_words()\n",
    "n_words = len(words)\n",
    "sample_word = words[int(random() * len(words))]\n",
    "print(\"\"\"\n",
    "      Found {n_words} words\n",
    "      Sample word:\n",
    "          {sample_word}\n",
    "      \"\"\".format(**locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameRecommender:\n",
    "    \"\"\"Base Class for producing name recommendations based on a list of liked\n",
    "    words from a user. There are possible ways to upgrade this base class and\n",
    "    they are marked with TODO.\n",
    "    \n",
    "    To use:\n",
    "        # Initialize\n",
    "        namer = NameRecommender(words, featurizer)\n",
    "        \n",
    "        # Example for pulling L2 recommendations for User 1\n",
    "        user1_features = namer.construct_user_features(['fox', 'box'], ['hello', 'abracadabra'])\n",
    "        namer.recommend_on_L2_similarity(user1_features, 10)\n",
    "        \n",
    "        # Example for pulling L-Infinity recommendations for User 1 after the above lines\n",
    "        namer.recommend_on_Linf_similarity(user1_features, 10)\n",
    "        \n",
    "        # Example for pulling L2 recommendations for User 2\n",
    "        user2_features = namer.construct_user_features(['hello', 'abracadabra'], ['fox', 'box'])\n",
    "        namer.recommend_on_L2_similarity(user2_features, 10)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, words, featurizer):\n",
    "        \"\"\"Initialize the Recommender language and features\n",
    "        \n",
    "        Args:\n",
    "            words: (list of Word objects), all words in this recommender's language\n",
    "            featurizer: (function) takes a Word object and returns a np.array featurizing the word\n",
    "        \"\"\"\n",
    "        self.words = words\n",
    "        self.featurizer = featurizer\n",
    "        self._construct_word_features()\n",
    "        \n",
    "        # Of the possible words limit to candidates to consider\n",
    "        self.candidates = [\n",
    "            word.written  \n",
    "            for word in words\n",
    "            if True # TODO remove undesireable words with non-alphabetic characters\n",
    "        ] \n",
    "        \n",
    "    def _construct_word_features(self):\n",
    "        \"\"\"Featurizes the dictionary for quick and easy comparison to later.\n",
    "        \"\"\"\n",
    "        self.features = dict((word.written, self.featurizer(word))\n",
    "                             for word in self.words)\n",
    "        # TODO add normalization to self.featurizer\n",
    "        \n",
    "    def construct_user_features(self, liked_words, disliked_words):\n",
    "        \"\"\"Constructs the User Features based on liked and disliked words\n",
    "        \n",
    "        Args:\n",
    "            liked_words: (list of str) the written words a user likes ie ['fox', 'box']\n",
    "            disliked_words: (list of str) the written words a user dislikes ie ['hello', 'fellow']\n",
    "            \n",
    "        Returns:\n",
    "            (np.array) average features of the user's words.\n",
    "        \"\"\"\n",
    "        token_liked_features = [\n",
    "            self.features[word]\n",
    "            for word in liked_words\n",
    "            if word in self.features\n",
    "        ]\n",
    "        liked_features = sum(token_liked_features) / float(len(token_liked_features))\n",
    "        \n",
    "        # TODO substract features based on disliked_words\n",
    "        \n",
    "        # TODO normalize the feature vector\n",
    "        \n",
    "        return liked_features\n",
    "        \n",
    "    def _recommend(self, similarity_function, user_features, n, threshold=0.0):\n",
    "        \"\"\"Core functionality that provides the recommendations based on the initialized\n",
    "        recommender and the described user.\n",
    "        \n",
    "        Args:\n",
    "            similarity_function: (function) takes in two feature vectors and returns a float\n",
    "            user_features: (np.array) a feature vector representing the user's tastes\n",
    "            n: (int), number of recommendations to return\n",
    "            \n",
    "        Kwargs:\n",
    "            threshold: (float) the tolerance of the best score\n",
    "            \n",
    "        Returns:\n",
    "            (list of str), a randomly ordered list of the candidates with the highest score\n",
    "        \"\"\"\n",
    "        Rank = namedtuple('Rank', ['word', 'score'])\n",
    "        \n",
    "        # This is the costly step, comparing a user feature to all other features\n",
    "        ranked_candidates = [\n",
    "            Rank(candidate, similarity_function(self.features[candidate], user_features))\n",
    "            for candidate in self.candidates\n",
    "        ]\n",
    "        ranked_candidates.sort(key=lambda candidate: candidate.score)\n",
    "        \n",
    "        # Find the best score and limit results to those within \n",
    "        best_score = ranked_candidates[0].score\n",
    "        top_candidates = [\n",
    "            candidate\n",
    "            for candidate in ranked_candidates\n",
    "            if candidate.score <= best_score + threshold\n",
    "        ]\n",
    "        print('Found ', len(top_candidates), 'top candidates to use.')\n",
    "        \n",
    "        # Shuffle the results for flavor and return TODO enable to change up results\n",
    "        #shuffle(top_candidates)\n",
    "        return [candidate.word for candidate in top_candidates[:n]]\n",
    "        \n",
    "    def recommend_on_L2_similarity(self, user_features, n, threshold=0.0):\n",
    "        \"\"\"Users the L2 norm for detecting the similarity between two feature vectors and\n",
    "        finds the best recommendations accordingly.\n",
    "        \n",
    "        Args:\n",
    "            user_features: (np.array) a feature vector representing the user's tastes\n",
    "            n: (int), number of recommendations to return\n",
    "            \n",
    "        Kwargs:\n",
    "            threshold: (float), the tolerance with which return results scoring within the\n",
    "                threhold of the best score\n",
    "            \n",
    "        Returns:\n",
    "            (list of str), a randomly ordered list of the candidates with the highest score\n",
    "        \"\"\"\n",
    "        def L2(features_1, features_2):\n",
    "            return sum((features_1 - features_2)**2)**0.5\n",
    "        \n",
    "        return self._recommend(L2, user_features, n, threshold)\n",
    "                \n",
    "    def recommend_on_Linf_similarity(self, user_features, n, threshold=0.0):\n",
    "        \"\"\"Users a modification of the L-inf norm for detecting the similarity between\n",
    "        two feature vectors and finds the best recommendations accordingly.\n",
    "        \n",
    "        Args:\n",
    "            user_features: (np.array) a feature vector representing the user's tastes\n",
    "            n: (int), number of recommendations to return\n",
    "            \n",
    "        Kwargs:\n",
    "            threshold: (float), the tolerance with which return results scoring within the\n",
    "                threhold of the best score\n",
    "\n",
    "        Returns:\n",
    "            (list of str), a randomly ordered list of the candidates with the highest score\n",
    "        \"\"\"\n",
    "        def Linf(features_1, features_2):\n",
    "            return sum(-1\n",
    "                       for (f1, f2) in zip(features_1, features_2)\n",
    "                       if f1 > 0 and f2 > 0\n",
    "                      )\n",
    "        \n",
    "        return self._recommend(Linf, user_features, n, threshold)\n",
    "    \n",
    "    def recommend_on_TODO_similarity(self, user_features, n):\n",
    "        \"\"\"If you'd like try a custom similarity ranker. See the above L2 and Linf\n",
    "        rankers for the implementation pattern.\n",
    "        \"\"\"\n",
    "        raise Exception('Not Implemented')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Handy Dandy local variable for creating featurizers.\n",
    "Create a mapping from phones to a feature number.\n",
    "\"\"\"\n",
    "def get_all_phones(words):\n",
    "    \"\"\"Gets\n",
    "    \"\"\"\n",
    "    phones = set([])\n",
    "    for word in words:\n",
    "        phones.update(word.phonetic)\n",
    "        \n",
    "    return list(phones)\n",
    "\n",
    "all_phones = get_all_phones(words)\n",
    "phone_to_id = dict((phone, i) for (phone, i) in zip(all_phones, range(len(all_phones))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OW1': 0, 'AW1': 1, 'CH': 2, 'JH': 3, 'AH2': 4, 'AY0': 5, 'OY0': 6, 'IY0': 7, 'T': 8, 'B': 9, 'AH1': 10, 'OW0': 11, 'ER1': 12, 'AO2': 13, 'UW0': 14, 'AY2': 15, 'ER2': 16, 'N': 17, 'D': 18, 'IH1': 19, 'AA1': 20, 'AO1': 21, 'OY1': 22, 'AW0': 23, 'AH0': 24, 'IH2': 25, 'Y': 26, 'AE2': 27, 'UW1': 28, 'IH0': 29, 'AE0': 30, 'EH2': 31, 'UH1': 32, 'OW2': 33, 'W': 34, 'Z': 35, 'S': 36, 'K': 37, 'M': 38, 'DH': 39, 'AW2': 40, 'EH1': 41, 'IY1': 42, 'V': 43, 'AE1': 44, 'AA2': 45, 'AA0': 46, 'F': 47, 'IY2': 48, 'G': 49, 'UW2': 50, 'AY1': 51, 'L': 52, 'UH2': 53, 'ER0': 54, 'EY2': 55, 'EY0': 56, 'UH0': 57, 'EH0': 58, 'R': 59, 'NG': 60, 'OY2': 61, 'SH': 62, 'ZH': 63, 'P': 64, 'EY1': 65, 'TH': 66, 'AO0': 67, 'HH': 68}\n"
     ]
    }
   ],
   "source": [
    "print(phone_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhyming_featurizer(word):\n",
    "    \"\"\"Basic featurizer looking for words that end the same.\n",
    "    \n",
    "    Args:\n",
    "        word: (Word object) \n",
    "        \n",
    "    Returns:\n",
    "        (np.array) with non-zero entries based on the ending phones of the word and its length\n",
    "    \"\"\"\n",
    "    features = np.zeros(len(phone_to_id) + 1)\n",
    "    \n",
    "    # TODO use the last 2 phones for more exact rhymes\n",
    "    if len(word.phonetic) >= 2:\n",
    "        features[phone_to_id[word.phonetic[-2]]] += 1\n",
    "        \n",
    "    features[phone_to_id[word.phonetic[-1]]] += 1\n",
    "    \n",
    "    # Adding an extra feature to keep words to roughly the same length\n",
    "    features[-1] = len(word.phonetic)\n",
    "    \n",
    "    return features\n",
    "\n",
    "rhyming_namer = NameRecommender(words, rhyming_featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  384 top candidates to use.\n",
      "Found  1899 top candidates to use.\n",
      "\n",
      "Rhyming Recommendations with only the highest scores based on seed words: ['fox', 'box', 'tax', 'fax', 'sacks'].\n",
      "\n",
      "Based on L2 Similarity:\n",
      "    ['arcs', 'arx', 'asks', 'backes', 'backs', 'bakes', 'balks', 'bask', 'basque', 'bax']\n",
      "    \n",
      "Based on Linf Similarity:\n",
      "    ['aardvarks', 'abex', 'academics', 'aches', 'acoustics', 'acrobatics', 'acrylics', 'acts(1)', 'adaptaplex', \"adaptec's\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test out the Rhyming Namer!\n",
    "\"\"\"\n",
    "liked_words = [\n",
    "    'fox',\n",
    "    'box',\n",
    "    'tax',\n",
    "    'fax',\n",
    "    'sacks'\n",
    "]\n",
    "disliked_words = [\n",
    "    'hello',\n",
    "    'fellow',\n",
    "]\n",
    "fox_features = rhyming_namer.construct_user_features(liked_words, disliked_words)\n",
    "fox_L2_rhymes = rhyming_namer.recommend_on_L2_similarity(fox_features, 10)\n",
    "fox_Linf_rhymes = rhyming_namer.recommend_on_Linf_similarity(fox_features, 10)\n",
    "print(\"\"\"\n",
    "Rhyming Recommendations with only the highest scores based on seed words: {liked_words}.\n",
    "\n",
    "Based on L2 Similarity:\n",
    "    {fox_L2_rhymes}\n",
    "    \n",
    "Based on Linf Similarity:\n",
    "    {fox_Linf_rhymes}\n",
    "\"\"\".format(**locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_featurizer(word):\n",
    "    \"\"\"Featurizer trying to match as many sounds as possible.\n",
    "    \n",
    "    Args:\n",
    "        word: (Word object) \n",
    "        \n",
    "    Returns:\n",
    "        (np.array) with non-zero entries based on the ending phones of the word and its length\n",
    "    \"\"\"\n",
    "    features = np.zeros(len(phone_to_id) + 1)\n",
    "    for phone in word.phonetic:\n",
    "        features[phone_to_id[phone]] += 1\n",
    "        \n",
    "    # TODO normalize features\n",
    "\n",
    "    return features\n",
    "\n",
    "matching_namer = NameRecommender(words, matching_featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  3 top candidates to use.\n",
      "\n",
      "Matching Recommendations based on seed words: ['glass'].\n",
      "\n",
      "Top Matches Based on L2 Similarity:\n",
      "    ['glas', 'glass', 'slag']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try a matching featurizer to get as many sounds as possible in the recommendations\n",
    "liked_words = [\n",
    "    'glass',\n",
    "]\n",
    "disliked_words = [\n",
    "    'hello',\n",
    "    'there',\n",
    "]\n",
    "glass_features = matching_namer.construct_user_features(liked_words, disliked_words)\n",
    "glass_L2_matches = matching_namer.recommend_on_L2_similarity(glass_features, 10)\n",
    "print(\"\"\"\n",
    "Matching Recommendations based on seed words: {liked_words}.\n",
    "\n",
    "Top Matches Based on L2 Similarity:\n",
    "    {glass_L2_matches}\n",
    "\"\"\".format(**locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  19 top candidates to use.\n",
      "\n",
      "Matching Recommendations based on seed words: ['glass'].\n",
      "\n",
      "Top Matches Based on L2 Similarity:\n",
      "    ['glas', 'glass', 'slag', 'gal', 'gallus', 'galus', 'gas', 'gass', 'glance', 'glassed']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's relax the threshold and see if we get more results\n",
    "glass_features = matching_namer.construct_user_features(liked_words, disliked_words)\n",
    "glass_L2_matches = matching_namer.recommend_on_L2_similarity(glass_features, 10, 1.0)\n",
    "print(\"\"\"\n",
    "Matching Recommendations based on seed words: {liked_words}.\n",
    "\n",
    "Top Matches Based on L2 Similarity:\n",
    "    {glass_L2_matches}\n",
    "\"\"\".format(**locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Group Discovery Time!\n",
    "\n",
    "What type of name recommender would you like to build?\n",
    "\n",
    "\n",
    "What type of features should it use?\n",
    "\n",
    "\n",
    "Build the featurizer and initalize the recommender as laid out below\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def football_featurizer(word):\n",
    "    \"\"\"Featurizer trying to match as many sounds as possible.\n",
    "    \n",
    "    Args:\n",
    "        word: (Word object) \n",
    "        \n",
    "    Returns:\n",
    "        (np.array) with non-zero entries based on the ending phones of the word and its length\n",
    "    \"\"\"\n",
    "    features = np.zeros(len(phone_to_id) + 1)\n",
    "    \n",
    "    # TODO\n",
    "\n",
    "    return features\n",
    "\n",
    "football_namer = NameRecommender(words, football_featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Group Discovery Time!\n",
    "\n",
    "Test the recommender by setting the liked words and disliked words and running!\n",
    "\"\"\"\n",
    "\n",
    "football_liked_words = ['steelers', 'bears', 'seahawks', 'rams', 'eagles', 'panthers']\n",
    "todo_disliked_words = []\n",
    "\n",
    "todo_user_features = TODO_namer.construct_user_features(liked_words, disliked_words)\n",
    "todo_L2_matches = TODO_namer.recommend_on_L2_similarity(todo_user_features, 10, 0.0)\n",
    "print(\"\"\"\n",
    "Matching Recommendations based on seed words: {todo_liked_words}.\n",
    "\n",
    "Top Matches Based on L2 Similarity:\n",
    "    {glass_L2_matches}\n",
    "\"\"\".format(**locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Word(written='bears', phonetic=['B', 'EH1', 'R', 'Z']), Word(written='eagles', phonetic=['IY1', 'G', 'AH0', 'L', 'Z']), Word(written='panthers', phonetic=['P', 'AE1', 'N', 'TH', 'ER0', 'Z']), Word(written='rams', phonetic=['R', 'AE1', 'M', 'Z']), Word(written='seahawks', phonetic=['S', 'IY1', 'HH', 'AO2', 'K', 'S']), Word(written='steelers', phonetic=['S', 'T', 'IY1', 'L', 'ER0', 'Z'])]\n",
      "Word(written='adame', phonetic=['AA0', 'D', 'AA1', 'M', 'IY0'])\n"
     ]
    }
   ],
   "source": [
    "print([word for word in words if word.written in ['steelers', 'bears', 'seahawks', 'rams', 'eagles', 'panthers']])\n",
    "print(words[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word(written='alaska', phonetic=['AH0', 'L', 'AE1', 'S', 'K', 'AH0'])\n",
      "Word(written='assam', phonetic=['AA2', 'S', 'AA1', 'M'])\n",
      "Word(written='lisbon', phonetic=['L', 'IH1', 'Z', 'B', 'AH0', 'N'])\n",
      "Word(written='santiago', phonetic=['S', 'AE2', 'N', 'T', 'IY0', 'AA1', 'G', 'OW0'])\n",
      "Word(written='sumatra', phonetic=['S', 'UW2', 'M', 'AA1', 'T', 'R', 'AH0'])\n",
      "Word(written='valdivia', phonetic=['V', 'AA0', 'L', 'D', 'IY1', 'V', 'IY0', 'AH0'])\n"
     ]
    }
   ],
   "source": [
    "found = [word for word in words if word.written in ['valdivia', 'alaska', 'lisbon', 'santiago', 'sumatra', 'assam']]\n",
    "for word in found:\n",
    "    print(word)\n",
    "         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
