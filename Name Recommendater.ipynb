{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import random\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines that could not be parsed:  1\n",
      "\n",
      "      Found 133851 words\n",
      "      Sample word:\n",
      "          Word(written='bromont', phonetic=['B', 'R', 'OW1', 'M', 'AA2', 'N', 'T'])\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "Word = namedtuple('Word', ['written', 'phonetic'])\n",
    "\n",
    "\n",
    "def load_words():\n",
    "    \"\"\"Loads the words from the CMU phonetic dictionary and parses them into Word objects\n",
    "    \n",
    "    Returns:\n",
    "        list, of Word objects \n",
    "    \"\"\"\n",
    "    words = []\n",
    "    bad_lines = 0\n",
    "    with open('data/cmudict-0.7b', 'rb') as dict_handle:\n",
    "        for line in dict_handle:\n",
    "            try:\n",
    "                line = line.decode(\"utf-8\") \n",
    "            except:\n",
    "                bad_lines += 1\n",
    "                continue\n",
    "                \n",
    "            if line[0] == ';' or len(line) < 2:\n",
    "                continue # Header or comment line\n",
    "\n",
    "            line_chunks = str(line[:-1]).split(' ')\n",
    "            written = line_chunks[0].lower()\n",
    "            phonetic = [phone for phone in line_chunks[1:] if len(phone) >= 1]\n",
    "            words.append(Word(written, phonetic))\n",
    "            \n",
    "    print('Number of lines that could not be parsed: ', bad_lines)\n",
    "    return words\n",
    "\n",
    "# Grab the words and check they loaded correctly.\n",
    "words = load_words()\n",
    "n_words = len(words)\n",
    "sample_word = words[int(random() * len(words))]\n",
    "print(\"\"\"\n",
    "      Found {n_words} words\n",
    "      Sample word:\n",
    "          {sample_word}\n",
    "      \"\"\".format(**locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameRecommender:\n",
    "    \"\"\"Base Class for producing name recommendations based on a list of liked\n",
    "    words from a user. There are possible ways to upgrade this base class and\n",
    "    they are marked with TODO.\n",
    "    \n",
    "    To use:\n",
    "        # Initialize\n",
    "        namer = NameRecommender(words, featurizer)\n",
    "        \n",
    "        # Example for pulling L2 recommendations for User 1\n",
    "        user1_features = namer.construct_user_features(['fox', 'box'], ['hello', 'abracadabra'])\n",
    "        namer.recommend_on_L2_similarity(user1_features, 10)\n",
    "        \n",
    "        # Example for pulling L-Infinity recommendations for User 1 after the above lines\n",
    "        namer.recommend_on_Linf_similarity(user1_features, 10)\n",
    "        \n",
    "        # Example for pulling L2 recommendations for User 2\n",
    "        user2_features = namer.construct_user_features(['hello', 'abracadabra'], ['fox', 'box'])\n",
    "        namer.recommend_on_L2_similarity(user2_features, 10)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, words, featurizer):\n",
    "        \"\"\"Initialize the Recommender language and features\n",
    "        \n",
    "        Args:\n",
    "            words: (list of Word objects), all words in this recommender's language\n",
    "            featurizer: (function) takes a Word object and returns a np.array featurizing the word\n",
    "        \"\"\"\n",
    "        self.words = words\n",
    "        self.featurizer = featurizer\n",
    "        self._construct_word_features()\n",
    "        \n",
    "        # Of the possible words limit to candidates to consider\n",
    "        self.candidates = [\n",
    "            word.written  \n",
    "            for word in words\n",
    "            if True # TODO remove undesireable words with non-alphabetic characters\n",
    "        ] \n",
    "        \n",
    "    def _construct_word_features(self):\n",
    "        \"\"\"Featurizes the dictionary for quick and easy comparison to later.\n",
    "        \"\"\"\n",
    "        self.features = dict((word.written, self.featurizer(word))\n",
    "                             for word in self.words)\n",
    "        # TODO add normalization to self.featurizer\n",
    "        \n",
    "    def construct_user_features(self, liked_words, disliked_words):\n",
    "        \"\"\"Constructs the User Features based on liked and disliked words\n",
    "        \n",
    "        Args:\n",
    "            liked_words: (list of str) the written words a user likes ie ['fox', 'box']\n",
    "            disliked_words: (list of str) the written words a user dislikes ie ['hello', 'fellow']\n",
    "            \n",
    "        Returns:\n",
    "            (np.array) average features of the user's words.\n",
    "        \"\"\"\n",
    "        token_liked_features = [\n",
    "            self.features[word]\n",
    "            for word in liked_words\n",
    "            if word in self.features\n",
    "        ]\n",
    "        liked_features = sum(token_liked_features) / float(len(token_liked_features))\n",
    "        \n",
    "        # TODO substract features based on disliked_words\n",
    "        \n",
    "        # TODO normalize the feature vector\n",
    "        \n",
    "        return liked_features\n",
    "        \n",
    "    def _recommend(self, similarity_function, user_features, n, threshold=0.0):\n",
    "        \"\"\"Core functionality that provides the recommendations based on the initialized\n",
    "        recommender and the described user.\n",
    "        \n",
    "        Args:\n",
    "            similarity_function: (function) takes in two feature vectors and returns a float\n",
    "            user_features: (np.array) a feature vector representing the user's tastes\n",
    "            n: (int), number of recommendations to return\n",
    "            \n",
    "        Kwargs:\n",
    "            threshold: (float) the tolerance of the best score\n",
    "            \n",
    "        Returns:\n",
    "            (list of str), a randomly ordered list of the candidates with the highest score\n",
    "        \"\"\"\n",
    "        Rank = namedtuple('Rank', ['word', 'score'])\n",
    "        \n",
    "        # This is the costly step, comparing a user feature to all other features\n",
    "        ranked_candidates = [\n",
    "            Rank(candidate, similarity_function(self.features[candidate], user_features))\n",
    "            for candidate in self.candidates\n",
    "        ]\n",
    "        ranked_candidates.sort(key=lambda candidate: candidate.score)\n",
    "        \n",
    "        # Find the best score and limit results to those within \n",
    "        best_score = ranked_candidates[0].score\n",
    "        top_candidates = [\n",
    "            candidate\n",
    "            for candidate in ranked_candidates\n",
    "            if candidate.score <= best_score + threshold\n",
    "        ]\n",
    "        print('Found ', len(top_candidates), 'top candidates to use.')\n",
    "        \n",
    "        # Shuffle the results for flavor and return TODO enable to change up results\n",
    "        #shuffle(top_candidates)\n",
    "        return [candidate.word for candidate in top_candidates[:n]]\n",
    "        \n",
    "    def recommend_on_L2_similarity(self, user_features, n, threshold=0.0):\n",
    "        \"\"\"Users the L2 norm for detecting the similarity between two feature vectors and\n",
    "        finds the best recommendations accordingly.\n",
    "        \n",
    "        Args:\n",
    "            user_features: (np.array) a feature vector representing the user's tastes\n",
    "            n: (int), number of recommendations to return\n",
    "            \n",
    "        Kwargs:\n",
    "            threshold: (float), the tolerance with which return results scoring within the\n",
    "                threhold of the best score\n",
    "            \n",
    "        Returns:\n",
    "            (list of str), a randomly ordered list of the candidates with the highest score\n",
    "        \"\"\"\n",
    "        def L2(features_1, features_2):\n",
    "            return sum((features_1 - features_2)**2)**0.5\n",
    "        \n",
    "        return self._recommend(L2, user_features, n, threshold)\n",
    "                \n",
    "    def recommend_on_Linf_similarity(self, user_features, n, threshold=0.0):\n",
    "        \"\"\"Users a modification of the L-inf norm for detecting the similarity between\n",
    "        two feature vectors and finds the best recommendations accordingly.\n",
    "        \n",
    "        Args:\n",
    "            user_features: (np.array) a feature vector representing the user's tastes\n",
    "            n: (int), number of recommendations to return\n",
    "            \n",
    "        Kwargs:\n",
    "            threshold: (float), the tolerance with which return results scoring within the\n",
    "                threhold of the best score\n",
    "\n",
    "        Returns:\n",
    "            (list of str), a randomly ordered list of the candidates with the highest score\n",
    "        \"\"\"\n",
    "        def Linf(features_1, features_2):\n",
    "            return sum(-1\n",
    "                       for (f1, f2) in zip(features_1, features_2)\n",
    "                       if f1 > 0 and f2 > 0\n",
    "                      )\n",
    "        \n",
    "        return self._recommend(Linf, user_features, n, threshold)\n",
    "    \n",
    "    def recommend_on_TODO_similarity(self, user_features, n):\n",
    "        \"\"\"If you'd like try a custom similarity ranker. See the above L2 and Linf\n",
    "        rankers for the implementation pattern.\n",
    "        \"\"\"\n",
    "        raise Exception('Not Implemented')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Handy Dandy local variable for creating featurizers.\n",
    "Create a mapping from phones to a feature number.\n",
    "\"\"\"\n",
    "def get_all_phones(words):\n",
    "    \"\"\"Gets\n",
    "    \"\"\"\n",
    "    phones = set([])\n",
    "    for word in words:\n",
    "        phones.update(word.phonetic)\n",
    "        \n",
    "    return list(phones)\n",
    "\n",
    "all_phones = get_all_phones(words)\n",
    "phone_to_id = dict((phone, i) for (phone, i) in zip(all_phones, range(len(all_phones))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhyming_featurizer(word):\n",
    "    \"\"\"Basic featurizer looking for words that end the same.\n",
    "    \n",
    "    Args:\n",
    "        word: (Word object) \n",
    "        \n",
    "    Returns:\n",
    "        (np.array) with non-zero entries based on the ending phones of the word and its length\n",
    "    \"\"\"\n",
    "    features = np.zeros(len(phone_to_id) + 1)\n",
    "    \n",
    "    # TODO use the last 2 phones for more exact rhymes\n",
    "    features[phone_to_id[word.phonetic[-1]]] = 1\n",
    "    \n",
    "    # Adding an extra feature to keep words to roughly the same length\n",
    "    features[-1] = len(word.phonetic)\n",
    "    \n",
    "    return features\n",
    "\n",
    "rhyming_namer = NameRecommender(words, rhyming_featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  1307 top candidates to use.\n",
      "Found  11319 top candidates to use.\n",
      "\n",
      "Rhyming Recommendations with only the highest scores based on seed words: ['fox', 'box', 'tax', 'fax', 'sacks'].\n",
      "\n",
      "Based on L2 Similarity:\n",
      "    [\"'course\", '+plus', 'abbas', 'abts', 'abyss', \"act's\", 'acts', 'addis', 'aegis', 'aerts']\n",
      "    \n",
      "Based on Linf Similarity:\n",
      "    ['\"in-quotes', \"'course\", \"'s\", '+plus', '...ellipsis', 'aardvarks', 'aase', 'abacus', 'abandonments', 'abatements']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test out the Rhyming Namer!\n",
    "\"\"\"\n",
    "liked_words = [\n",
    "    'fox',\n",
    "    'box',\n",
    "    'tax',\n",
    "    'fax',\n",
    "    'sacks'\n",
    "]\n",
    "disliked_words = [\n",
    "    'hello',\n",
    "    'fellow',\n",
    "]\n",
    "fox_features = rhyming_namer.construct_user_features(liked_words, disliked_words)\n",
    "fox_L2_rhymes = rhyming_namer.recommend_on_L2_similarity(fox_features, 10)\n",
    "fox_Linf_rhymes = rhyming_namer.recommend_on_Linf_similarity(fox_features, 10)\n",
    "print(\"\"\"\n",
    "Rhyming Recommendations with only the highest scores based on seed words: {liked_words}.\n",
    "\n",
    "Based on L2 Similarity:\n",
    "    {fox_L2_rhymes}\n",
    "    \n",
    "Based on Linf Similarity:\n",
    "    {fox_Linf_rhymes}\n",
    "\"\"\".format(**locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_featurizer(word):\n",
    "    \"\"\"Featurizer trying to match as many sounds as possible.\n",
    "    \n",
    "    Args:\n",
    "        word: (Word object) \n",
    "        \n",
    "    Returns:\n",
    "        (np.array) with non-zero entries based on the ending phones of the word and its length\n",
    "    \"\"\"\n",
    "    features = np.zeros(len(phone_to_id) + 1)\n",
    "    for phone in word.phonetic:\n",
    "        features[phone_to_id[phone]] += 1\n",
    "\n",
    "    return features\n",
    "\n",
    "matching_namer = NameRecommender(words, matching_featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  3 top candidates to use.\n",
      "\n",
      "Matching Recommendations based on seed words: ['glass'].\n",
      "\n",
      "Top Matches Based on L2 Similarity:\n",
      "    ['glas', 'glass', 'slag']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try a matching featurizer to get as many sounds as possible in the recommendations\n",
    "liked_words = [\n",
    "    'glass',\n",
    "]\n",
    "disliked_words = [\n",
    "    'hello',\n",
    "    'there',\n",
    "]\n",
    "glass_features = matching_namer.construct_user_features(liked_words, disliked_words)\n",
    "glass_L2_matches = matching_namer.recommend_on_L2_similarity(glass_features, 10)\n",
    "print(\"\"\"\n",
    "Matching Recommendations based on seed words: {liked_words}.\n",
    "\n",
    "Top Matches Based on L2 Similarity:\n",
    "    {glass_L2_matches}\n",
    "\"\"\".format(**locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  19 top candidates to use.\n",
      "\n",
      "Matching Recommendations based on seed words: ['glass'].\n",
      "\n",
      "Top Matches Based on L2 Similarity:\n",
      "    ['glas', 'glass', 'slag', 'gal', 'gallus', 'galus', 'gas', 'gass', 'glance', 'glassed']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's relax the threshold\n",
    "\n",
    "glass_features = matching_namer.construct_user_features(liked_words, disliked_words)\n",
    "glass_L2_matches = matching_namer.recommend_on_L2_similarity(glass_features, 10, 1.0)\n",
    "print(\"\"\"\n",
    "Matching Recommendations based on seed words: {liked_words}.\n",
    "\n",
    "Top Matches Based on L2 Similarity:\n",
    "    {glass_L2_matches}\n",
    "\"\"\".format(**locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
